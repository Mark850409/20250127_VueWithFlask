from sklearn.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, accuracy_score, precision_score, \
    recall_score, f1_score, classification_report
import numpy as np
from sqlalchemy import create_engine
from flask import Flask, request, abort
import json
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (MessageEvent, TextMessage, TextSendMessage, FollowEvent, UnfollowEvent,
                            LocationMessage, CarouselTemplate, CarouselColumn, PostbackAction, MessageAction, URIAction,
                            TemplateSendMessage)
from config import setting
import random
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd
from scipy.stats import pearsonr
from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity as cosine_similarity_metric

# ä½ çš„Google Places APIé‡‘é‘°
api_key = setting.api_key

app = Flask(__name__)

# è¨­ç½®æ‚¨çš„Channel Access Tokenå’ŒChannel Secret
ACCESS_TOKEN = setting.ACCESS_TOKEN
SECRET = setting.SECRET

line_bot_api = LineBotApi(ACCESS_TOKEN)
handler = WebhookHandler(SECRET)

# ===========================================================
# æ¸¬è©¦è³‡æ–™é›†
# ===========================================================
# # ç”Ÿæˆ10000å®¶åº—å®¶çš„åç¨±
# restaurant_names = [f'åº—å®¶{i}' for i in range(1, 10001)]
#
# # ç”Ÿæˆ10000å€‹éš¨æ©Ÿäº‚æ•¸ä½œç‚ºåº—å®¶çš„ID
# restaurant_ids = random.sample(range(10000, 99999), 10000)
#
# # ç”Ÿæˆ100å€‹ä½¿ç”¨è€…å°10000å®¶åº—å®¶çš„è©•åˆ†è³‡æ–™
# ratings_data = {
#     'user_id': [random.randint(1, 1000) for _ in range(10000)],
#     'restaurant_name': restaurant_names,
#     'restaurant_id': restaurant_ids,
#     'rating': [random.randint(1, 5) for _ in range(10000)],
#     'city': ['å°åŒ—å¸‚'] * 10000
# }

# # ç”Ÿæˆ100å€‹ä½¿ç”¨è€…å°10000å®¶åº—å®¶çš„è©•åˆ†è³‡æ–™
# ratings_data = {
#     'user_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
#     'restaurant_name': ['å¯ä¸å¯ç†Ÿæˆç´…èŒ¶ (å°åŒ—é€šåŒ–åº—)', 'å¥½äº†å•¦ç´…èŒ¶å†° (é¥’æ²³å…«å¾·åº—)', 'æ°´å··èŒ¶å¼„ (å—äº¬ä¸‰æ°‘åº—)',
#                         'æ¸…å¿ƒç¦å…¨ (ä¿¡ç¾©æ°¸å‰åº—)', 'COMEBUY (å°åŒ—å¸‚åºœåº—)', 'TEATOP ç¬¬ä¸€å‘³ (å°åŒ—é€šåŒ–åº—)',
#                         'åŒ—æŠ•ç´…èŒ¶ (å¤§å®‰åº—)', 'å˜‰ç¾©ç´…èŒ¶ (å°åŒ—é¥’æ²³åº—)', 'å¯Œå£«å ‚-æ—¥æœ¬é®®å¥¶èŒ¶é£²', 'æœéœ¸èŒ¶ (å°åŒ—é€šåŒ–åº—)'],
#     'restaurant_id': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],
#     'rating': [1, 2, 3, 1, 5, 1, 4, 5, 1, 3],
#     'city': ['å°åŒ—å¸‚'] * 10
# }
#
# # # ç”Ÿæˆåº—å®¶çš„åœ°ç†ä½ç½®å’Œç¶²å€è³‡æ–™
# restaurants_data = {
#     'restaurant_id': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],
#     'latitude': [round(random.uniform(25.02, 25.05), 4) for _ in range(10)],
#     'longitude': [round(random.uniform(121.55, 121.58), 4) for _ in range(10)],
#     'name': ['å¯ä¸å¯ç†Ÿæˆç´…èŒ¶ (å°åŒ—é€šåŒ–åº—)', 'å¥½äº†å•¦ç´…èŒ¶å†° (é¥’æ²³å…«å¾·åº—)', 'æ°´å··èŒ¶å¼„ (å—äº¬ä¸‰æ°‘åº—)',
#                         'æ¸…å¿ƒç¦å…¨ (ä¿¡ç¾©æ°¸å‰åº—)', 'COMEBUY (å°åŒ—å¸‚åºœåº—)', 'TEATOP ç¬¬ä¸€å‘³ (å°åŒ—é€šåŒ–åº—)',
#                         'åŒ—æŠ•ç´…èŒ¶ (å¤§å®‰åº—)', 'å˜‰ç¾©ç´…èŒ¶ (å°åŒ—é¥’æ²³åº—)', 'å¯Œå£«å ‚-æ—¥æœ¬é®®å¥¶èŒ¶é£²', 'æœéœ¸èŒ¶ (å°åŒ—é€šåŒ–åº—)'],
#     'redirection_url': ['http://google.com'] * 10,
#     'navigation_url': ['http://google.com'] * 10
# }

# # ç”Ÿæˆ10000å®¶åº—å®¶çš„åç¨±å’ŒID
# restaurant_names = [f'åº—å®¶{i}' for i in range(1, 10001)]
# restaurant_ids = random.sample(range(10000, 99999), 10000)
#
# # ç”Ÿæˆåº—å®¶çš„åœ°ç†ä½ç½®å’Œç¶²å€è³‡æ–™
# restaurants_data = {
#     'restaurant_id': restaurant_ids,
#     'latitude': [round(random.uniform(25.0, 25.1), 4) for _ in range(10000)],
#     'longitude': [round(random.uniform(121.5, 121.6), 4) for _ in range(10000)],
#     'name': restaurant_names,
#     'redirection_url': ['http://google.com'] * 10000,
#     'navigation_url': ['http://google.com'] * 10000
# }
#
# # ç”Ÿæˆ100å€‹ä½¿ç”¨è€…ID
# user_ids = list(range(1, 101))
#
# # ç”Ÿæˆè©•åˆ†è³‡æ–™
# ratings_data = {
#     'user_id': [],
#     'restaurant_name': [],
#     'restaurant_id': [],
#     'rating': [],
#     'city': []
# }
#
# for user_id in user_ids:
#     # éš¨æ©Ÿé¸æ“‡æ¯ä½ä½¿ç”¨è€…è©•è«–çš„åº—å®¶æ•¸é‡ï¼Œå‡è¨­ç‚º5è‡³20å®¶åº—å®¶
#     idx = random.randint(0, 9)  # éš¨æ©Ÿé¸æ“‡åº—å®¶è³‡æ–™çš„ç´¢å¼•
#     ratings_data['user_id'].append(user_id)
#     ratings_data['restaurant_name'].append(restaurants_data['name'][idx])
#     ratings_data['restaurant_id'].append(restaurants_data['restaurant_id'][idx])
#     ratings_data['rating'].append(random.randint(1, 5))  # éš¨æ©Ÿç”Ÿæˆè©•åˆ†
#     ratings_data['city'].append('å°åŒ—å¸‚')  # å‡è¨­éƒ½åœ¨å°åŒ—å¸‚
#
# ratings_df = pd.DataFrame(ratings_data)
# print(ratings_df)
# restaurants_df = pd.DataFrame(restaurants_data)
# print(restaurants_df)
# # è³‡æ–™é›†åˆä½µ
# merged_df = pd.merge(ratings_df, restaurants_df, on='restaurant_id')
#
# # å»ºç«‹é¤å»³çŸ©é™£
# user_restaurant_matrix = merged_df.pivot_table(index='user_id', columns='restaurant_id', values='rating').fillna(0)
#
# # å°‡è³‡æ–™é›†æ‹†åˆ†ç‚ºè¨“ç·´é›†èˆ‡æ¸¬è©¦é›†
# train_data, test_data = train_test_split(ratings_df, test_size=0.5, random_state=42)
#
# # å»ºç«‹ç”¨æˆ·-é¤å»³çŸ©é™£ï¼Œä½¿ç”¨ç»¼åˆè©•åˆ†
# train_user_restaurant_matrix = ratings_df.pivot_table(index='user_id', columns='restaurant_id',
#                                                       values='rating').fillna(0)

# ===========================================================
# å¾è³‡æ–™åº«å–å¾—è³‡æ–™é›†
# ===========================================================

# å»ºç«‹é€£ç·š
connect_ibfo = setting.SQLALCHEMY_DATABASE_URI
engine = create_engine(connect_ibfo)

# å–å¾—è©•åˆ†è³‡æ–™é›†
ratings_df = pd.read_sql('''select GMRW.id,GMRW.place_id,GMRW.restaurant_name,GMRW.rating,GMRW.composite_score,GMRW.user,RTL.city,RTL.city_CN,RTL.distance,RTL.review_number
from google_maps_review_with_selenium GMRW
JOIN restaurant_type_list  RTL ON  RTL.id=GMRW.id
where confidence>=0.7
''', con=engine)

# å»ºç«‹userå°æ‡‰IDçš„è¡¨æ ¼ï¼Œå¾1é–‹å§‹ç·¨è™Ÿ
unique_users = ratings_df['user'].unique()
user_to_id = {user: idx + 1 for idx, user in enumerate(unique_users)}

# ä½¿ç”¨ user_to_id æ›¿æ¢ 'user' åˆ—ä¸­çš„å€¼
ratings_df['user_id'] = ratings_df['user'].map(user_to_id)

# å–å¾—é¤å»³è³‡æ–™é›†
restaurants_df = pd.read_sql(
    "SELECT * FROM ConvertNameToPlaceID WHERE navigation_url<>'No navigation found' and place_id is not null",
    con=engine)

# å–å¾—ç­†æ•¸è³‡æ–™é›†
count_data = pd.read_sql(
    "SELECT count(*) as count from restaurant_type_list",
    con=engine)

count_df = pd.DataFrame(count_data)

# å»ºç«‹è©•åˆ†è³‡æ–™é›†
ratings_data = {
    'user_id': ratings_df['user_id'],
    'restaurant_id': ratings_df['place_id'],
    'restaurant_name': ratings_df['restaurant_name'],
    'rating': ratings_df['rating'],
    'sentiment_score': ratings_df['composite_score'],
    'city': ratings_df['city_CN'],
    'distance': ratings_df['distance'],
    'review_number': ratings_df['review_number']
}
ratings_df = pd.DataFrame(ratings_data)

# å»ºç«‹é¤å»³è³‡æ–™é›†
restaurants_data = {
    'restaurant_id': restaurants_df['place_id'],
    'latitude': restaurants_df['latitude'],
    'longitude': restaurants_df['longitude'],
    'name': restaurants_df['place_names'],
    'redirection_url': restaurants_df['redirection_url'],
    'navigation_url': restaurants_df['navigation_url'],
}
restaurants_df = pd.DataFrame(restaurants_data)

# å»ºç«‹é¤å»³åç¨±å°æ‡‰IDçš„è¡¨æ ¼
name_to_id = {row['name']: row['restaurant_id'] for _, row in restaurants_df.iterrows()}

# å»ºç«‹é¤å»³IDå°æ‡‰é¤å»³åç¨±çš„è¡¨æ ¼
id_to_name = {row['restaurant_id']: row['name'] for _, row in restaurants_df.iterrows()}

# å»ºç«‹foodpandaé¤å»³URLå°æ‡‰é¤å»³IDçš„è¡¨æ ¼
redirection_url_to_id = {row['restaurant_id']: row['redirection_url'] for _, row in restaurants_df.iterrows()}

# å»ºç«‹googlemapå°èˆªå°æ‡‰é¤å»³IDçš„è¡¨æ ¼
navigation_url_to_id = {row['restaurant_id']: row['navigation_url'] for _, row in restaurants_df.iterrows()}

# å»ºç«‹cityå°æ‡‰é¤å»³IDçš„è¡¨æ ¼
city_url_to_id = {row['restaurant_id']: row['city'] for _, row in ratings_df.iterrows()}

# è³‡æ–™é›†åˆä½µ
merged_df = pd.merge(ratings_df, restaurants_df, on='restaurant_id')

# ===========================================================
# æƒ…æ„Ÿåˆ†æ+é¤å»³è©•åˆ†+è·é›¢ä½¿ç”¨+ç€è¦½æ¬¡æ•¸(å®šç¾©æ¬Šé‡)
# ===========================================================
# å®šç¾©åˆå§‹æ¬Šé‡
base_rating_weight = 0.1
base_overall_sentiment_weight = 0.1
base_distance_weight = 0.4

# æ­£è¦åŒ–é¤å»³è©•åˆ†ã€è·é›¢ã€ç€è¦½é‡
scaler = MinMaxScaler()
ratings_df['normalized_rating'] = scaler.fit_transform(ratings_df[['rating']])
ratings_df['normalized_distance'] = scaler.fit_transform(ratings_df[['distance']])
ratings_df['normalized_review_number'] = scaler.fit_transform(ratings_df[['review_number']])

print(ratings_df['normalized_rating'])
print(ratings_df['normalized_distance'])
print(ratings_df['normalized_review_number'])

# å‹•æ…‹èª¿æ•´æ¬Šé‡ï¼Œä½¿ç”¨æŒ‡æ•¸å‡½æ•¸æˆ–å…¶ä»–éç·šæ€§å‡½æ•¸
ratings_df['dynamic_rating_weight'] = np.exp(ratings_df['normalized_rating']) * base_rating_weight
ratings_df['dynamic_sentiment_weight'] = np.exp(ratings_df['sentiment_score']) * base_overall_sentiment_weight
ratings_df['dynamic_distance_weight'] = np.exp(-ratings_df['normalized_distance']) * base_distance_weight
ratings_df['dynamic_review_number_weight'] = np.exp(ratings_df['normalized_review_number'])

# å°ç€è¦½é‡æ¬Šé‡é€²è¡Œæ­£è¦åŒ–ï¼Œç¢ºä¿ä¸è¶…é1
max_dynamic_review_number_weight = ratings_df['dynamic_review_number_weight'].max()
ratings_df['dynamic_review_number_weight'] = ratings_df['dynamic_review_number_weight'] / max_dynamic_review_number_weight

print(ratings_df[['dynamic_rating_weight', 'dynamic_sentiment_weight','dynamic_distance_weight','dynamic_review_number_weight']])
# ç¢ºä¿æ¬Šé‡ä¹‹å’Œç‚º1
total_weight = (
    ratings_df['dynamic_rating_weight'] +
    ratings_df['dynamic_sentiment_weight'] +
    ratings_df['dynamic_distance_weight'] +
    ratings_df['dynamic_review_number_weight']
)
ratings_df['dynamic_rating_weight'] /= total_weight
ratings_df['dynamic_sentiment_weight'] /= total_weight
ratings_df['dynamic_distance_weight'] /= total_weight
ratings_df['dynamic_review_number_weight'] /= total_weight

# è¨ˆç®—æœªæ­£è¦åŒ–çš„ç¶œåˆè©•åˆ†
ratings_df['unscaled_combined_score'] = (
    ratings_df['normalized_rating'] * ratings_df['dynamic_rating_weight'] +
    ratings_df['sentiment_score'] * ratings_df['dynamic_sentiment_weight'] +
    ratings_df['normalized_distance'] * ratings_df['dynamic_distance_weight'] +
    ratings_df['normalized_review_number'] * ratings_df['dynamic_review_number_weight']
)

# æ­£è¦åŒ–ç¶œåˆè©•åˆ†ï¼Œç¢ºä¿åœ¨0åˆ°1ä¹‹é–“
scaler_combined = MinMaxScaler()
ratings_df['weighted_combined_score'] = scaler_combined.fit_transform(ratings_df[['unscaled_combined_score']])

# å°‡è³‡æ–™é›†æ‹†åˆ†ç‚ºè¨“ç·´é›†èˆ‡æ¸¬è©¦é›†
train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)

# å»ºç«‹ç”¨æˆ·-é¤å»³çŸ©é™£ï¼Œä½¿ç”¨ç»¼åˆè©•åˆ†
train_user_restaurant_matrix = ratings_df.pivot_table(index='user_id', columns='restaurant_id',
                                                     values='weighted_combined_score').fillna(0)

# ===========================================================
# æƒ…æ„Ÿåˆ†æ+é¤å»³è©•åˆ†+è·é›¢ä½¿ç”¨(å®šç¾©æ¬Šé‡)
# ===========================================================
# # å®šç¾©åˆå§‹æ¬Šé‡
# base_rating_weight = 0.2
# base_overall_sentiment_weight = 0.2
# base_distance_weight = 0.6
# # æ­£è¦åŒ–é¤å»³è©•åˆ†ã€è·é›¢
# scaler = MinMaxScaler()
# ratings_df['normalized_rating'] = scaler.fit_transform(ratings_df[['rating']])
# ratings_df['normalized_distance'] = scaler.fit_transform(ratings_df[['distance']])
#
# # å‹•æ…‹èª¿æ•´æ¬Šé‡ï¼Œä½¿ç”¨æŒ‡æ•¸å‡½æ•¸æˆ–å…¶ä»–éç·šæ€§å‡½æ•¸
# ratings_df['dynamic_rating_weight'] = np.exp(ratings_df['normalized_rating']) * base_rating_weight
# ratings_df['dynamic_sentiment_weight'] = np.exp(ratings_df['sentiment_score']) * base_overall_sentiment_weight
# #ratings_df['dynamic_distance_weight'] = np.exp(ratings_df['normalized_distance']) * base_distance_weight
# ratings_df['dynamic_distance_weight'] = np.exp(-ratings_df['normalized_distance'])* base_distance_weight  # åè½‰è·é›¢çš„æ­£è¦åŒ–å€¼
#
# # ç¢ºä¿æ¬Šé‡ä¹‹å’Œç‚º1
# total_weight = (
#     ratings_df['dynamic_rating_weight'] +
#     ratings_df['dynamic_sentiment_weight'] +
#     ratings_df['dynamic_distance_weight']
# )
# ratings_df['dynamic_rating_weight'] /= total_weight
# ratings_df['dynamic_sentiment_weight'] /= total_weight
# ratings_df['dynamic_distance_weight'] /= total_weight
#
# # è¨ˆç®—æœªæ­£è¦åŒ–çš„ç¶œåˆè©•åˆ†
# ratings_df['unscaled_combined_score'] = (
#     ratings_df['normalized_rating'] * ratings_df['dynamic_rating_weight'] +
#     ratings_df['sentiment_score'] * ratings_df['dynamic_sentiment_weight'] +
#     ratings_df['normalized_distance'] * ratings_df['dynamic_distance_weight']
# )
#
# # æ­£è¦åŒ–ç¶œåˆè©•åˆ†ï¼Œç¢ºä¿åœ¨0åˆ°1ä¹‹é–“
# scaler_combined = MinMaxScaler()
# ratings_df['weighted_combined_score'] = scaler_combined.fit_transform(ratings_df[['unscaled_combined_score']])
#
# # å°‡è³‡æ–™é›†æ‹†åˆ†ç‚ºè¨“ç·´é›†èˆ‡æ¸¬è©¦é›†
# train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)
#
# # å»ºç«‹ç”¨æˆ·-é¤å»³çŸ©é™£ï¼Œä½¿ç”¨ç»¼åˆè©•åˆ†
# train_user_restaurant_matrix = ratings_df.pivot_table(index='user_id', columns='restaurant_id',
#                                                       values='weighted_combined_score').fillna(0)
# ===========================================================
# # æƒ…æ„Ÿåˆ†æ+é¤å»³è©•åˆ†(å®šç¾©æ¬Šé‡)
# ===========================================================

# å®šç¾©åˆå§‹æ¬Šé‡
base_rating_weight = 0.7
base_overall_sentiment_weight = 0.3

# æ­£è¦åŒ–é¤å»³è©•åˆ†ã€æƒ…æ„Ÿåˆ†æ•¸
scaler = MinMaxScaler()
ratings_df['normalized_rating'] = scaler.fit_transform(ratings_df[['rating']])
ratings_df['normalized_sentiment_score'] = scaler.fit_transform(ratings_df[['sentiment_score']])

# å‹•æ…‹èª¿æ•´æ¬Šé‡ï¼Œä½¿ç”¨æŒ‡æ•¸å‡½æ•¸æˆ–å…¶ä»–éç·šæ€§å‡½æ•¸
ratings_df['dynamic_rating_weight'] = np.exp(ratings_df['normalized_rating']) * base_rating_weight
ratings_df['dynamic_sentiment_weight'] = np.exp(
    ratings_df['normalized_sentiment_score']) * base_overall_sentiment_weight

# ç¢ºä¿æ¬Šé‡ä¹‹å’Œç‚º1
total_weight = ratings_df['dynamic_rating_weight'] + ratings_df['dynamic_sentiment_weight']
ratings_df['dynamic_rating_weight'] /= total_weight
ratings_df['dynamic_sentiment_weight'] /= total_weight

# æ‰“å°æˆ–å­˜å„²å‹•æ…‹æ¬Šé‡
print(ratings_df[['dynamic_rating_weight', 'dynamic_sentiment_weight']])

# è¨ˆç®—æœªæ­£è¦åŒ–çš„ç¶œåˆè©•åˆ†
ratings_df['unscaled_combined_score'] = (
        ratings_df['normalized_rating'] * ratings_df['dynamic_rating_weight'] +
        ratings_df['sentiment_score'] * ratings_df['dynamic_sentiment_weight']
)

# æ­£è¦åŒ–ç¶œåˆè©•åˆ†ï¼Œç¢ºä¿åœ¨0åˆ°1ä¹‹é–“
scaler_combined = MinMaxScaler()
ratings_df['weighted_combined_score'] = scaler_combined.fit_transform(ratings_df[['unscaled_combined_score']])

# å°‡è³‡æ–™é›†æ‹†åˆ†ç‚ºè¨“ç·´é›†èˆ‡æ¸¬è©¦é›†
train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)

# å»ºç«‹ç”¨æˆ·-é¤å»³çŸ©é™£ï¼Œä½¿ç”¨ç»¼åˆè©•åˆ†
train_user_restaurant_matrix = ratings_df.pivot_table(index='user_id', columns='restaurant_id',
                                                      values='weighted_combined_score').fillna(0)


# ===========================================================
# æ¨¡å‹è¨“ç·´é–‹å§‹
# ===========================================================

# è¨“ç·´KNNæ¨¡å‹
knn = NearestNeighbors(metric='cosine', algorithm='brute')
knn.fit(train_user_restaurant_matrix.values)


# è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
def cosine_similarity_predict(user_vector, similar_user_vector):
    return cosine_similarity_metric(user_vector.reshape(1, -1), similar_user_vector.reshape(1, -1)).flatten()[0]


# è¨ˆç®—çš®çˆ¾æ£®ä¿‚æ•¸
def pearson_correlation_predict(user_vector, similar_user_vector):
    if np.all(user_vector == user_vector[0]) or np.all(similar_user_vector == similar_user_vector[0]):
        return 0
    else:
        return pearsonr(user_vector, similar_user_vector)[0]


# è¨ˆç®—æ­å¹¾é‡Œå¾—è·é›¢
def euclidean_similarity_predict(user_vector, similar_user_vector):
    return 1 / (1 + euclidean_distances(user_vector.reshape(1, -1), similar_user_vector.reshape(1, -1)).flatten()[0])


# è¨ˆç®—æ›¼å“ˆé “è·é›¢
def manhattan_similarity_predict(user_vector, similar_user_vector):
    return 1 / (1 + manhattan_distances(user_vector.reshape(1, -1), similar_user_vector.reshape(1, -1)).flatten()[0])


# è¨ˆç®—æ¬Šé‡ä¸¦å°‡é€™4å€‹å€¼åŠ ç¸½
def combined_similarity_predict(cosine_sim, pearson_coef, euclidean_sim, manhattan_sim):
    return cosine_sim * 0.4 + pearson_coef * 0.3 + euclidean_sim * 0.2 + manhattan_sim * 0.1


def predict(user_id, restaurant_id, method='cosine'):
    if user_id not in train_user_restaurant_matrix.index or restaurant_id not in train_user_restaurant_matrix.columns:
        return None

    user_index = train_user_restaurant_matrix.index.get_loc(user_id)
    n_neighbors = min(num_recommendations * random.randint(1, 50), train_user_restaurant_matrix.shape[0])
    knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')
    knn.fit(train_user_restaurant_matrix.values)

    # å–å‡ºè·é›¢è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
    distances, indices = knn.kneighbors(train_user_restaurant_matrix.iloc[user_index, :].values.reshape(1, -1))

    # è¨­å®šåˆå§‹å€¼
    ratings_sum = 0
    similarity_sum = 0

    # è¼¸å‡ºæ¯å€‹é„°å±…çš„ç›¸ä¼¼åº¦å’Œè²¢ç»
    neighbor_contributions = []

    # é€éä¸åŒæ–¹å¼è¨ˆç®—ç›¸ä¼¼åº¦
    for i in range(1, len(distances.flatten())):
        similar_user_id = train_user_restaurant_matrix.index[indices.flatten()[i]]
        if pd.notna(train_user_restaurant_matrix.loc[similar_user_id, restaurant_id]):
            user_vector = train_user_restaurant_matrix.loc[user_id].values
            similar_user_vector = train_user_restaurant_matrix.loc[similar_user_id].values
            # é¤˜å¼¦ç›¸ä¼¼åº¦
            if method == 'cosine':
                sim = cosine_similarity_predict(user_vector, similar_user_vector)
            # çš®çˆ¾æ£®ä¿‚æ•¸
            elif method == 'pearson':
                sim = pearson_correlation_predict(user_vector, similar_user_vector)
            # æ­å¹¾é‡Œå¾—è·é›¢
            elif method == 'euclidean':
                sim = euclidean_similarity_predict(user_vector, similar_user_vector)
            # æ›¼å“ˆé “è·é›¢
            elif method == 'manhattan':
                sim = manhattan_similarity_predict(user_vector, similar_user_vector)
            # ä¾ç…§æ¬Šé‡è¨ˆç®—é€™4å€‹å€¼çš„åŠ ç¸½
            elif method == 'combined':
                cosine_sim = cosine_similarity_predict(user_vector, similar_user_vector)
                pearson_coef = pearson_correlation_predict(user_vector, similar_user_vector)
                euclidean_sim = euclidean_similarity_predict(user_vector, similar_user_vector)
                manhattan_sim = manhattan_similarity_predict(user_vector, similar_user_vector)
                sim = combined_similarity_predict(cosine_sim, pearson_coef, euclidean_sim, manhattan_sim)
            else:
                raise ValueError(
                    "Invalid method. Choose from 'cosine', 'pearson', 'euclidean', 'manhattan', or 'combined'.")

            rating = train_user_restaurant_matrix.loc[similar_user_id, restaurant_id]
            ratings_sum += rating * sim
            similarity_sum += sim
            neighbor_contributions.append((similar_user_id, restaurant_id, sim, ratings_sum, similarity_sum))

    if similarity_sum == 0:
        return None
    else:
        predicted_rating = ratings_sum / similarity_sum
        print("=============================")
        print(f"æ¨¡å‹é æ¸¬åˆ†æ•¸ç‚º: {predicted_rating}")
        print(f"åŠ æ¬Šè©•åˆ†ç‚º: {ratings_sum}")
        print(f"ç›¸ä¼¼åº¦ç¸½åˆ†ç‚º: {similarity_sum}")
        print("=============================")
        # print("é„°å±…çš„ç›¸ä¼¼åº¦å’ŒåŠ æ¬Šè©•åˆ†è²¢ç»ç‚º:")
        # for neighbor in neighbor_contributions:
        #     print(
        #         f"ä½¿ç”¨è€…: {neighbor[0]}, é¤å»³: {neighbor[1]},ç›¸ä¼¼åº¦é æ¸¬è©•åˆ†: {neighbor[2]}, åŠ æ¬Šè©•åˆ†: {neighbor[3]}, ç›¸ä¼¼åº¦ç¸½åˆ†: {neighbor[4]}")
        # print("=============================")
        return predicted_rating


# è©•ä¼°æ¨¡å‹æº–ç¢ºåº¦
def evaluate_model():
    y_true = []
    y_pred = []

    for _, row in test_data.iterrows():
        user_id = row['user_id']
        restaurant_id = row['restaurant_id']
        true_rating = row['weighted_combined_score']
        predicted_rating = predict(user_id, restaurant_id)  # ä½¿ç”¨ predict_function ä¾†é æ¸¬è©•åˆ†
        if predicted_rating is not None:
            y_true.append(true_rating)
            y_pred.append(predicted_rating)
            # print(f"è©•åˆ†é æ¸¬ {predicted_rating}å·²åŠ å…¥!!!")
        else:
            print(f"æœªèƒ½é æ¸¬ {user_id} å’Œ {restaurant_id} çš„è©•åˆ†ï¼Œå¯èƒ½ç”±æ–¼è³‡æ–™ä¸è¶³æˆ–æœªçŸ¥çš„çµ„åˆã€‚")
    # æª¢æŸ¥ y_true å’Œ y_pred æ˜¯å¦ç‚ºç©º
    if not y_true or not y_pred:
        print("ç³Ÿç³•!!!è³‡æ–™ä¸å¤ è€¶!!!")
        return None

    # è¨ˆç®—RMSEå’ŒMAE
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)

    # è¨­å®šè©•åˆ†é–¾å€¼è½‰æ›
    threshold = 0.5  # ä½¿ç”¨å¹³å‡å€¼ä½œç‚ºè©•åˆ†é–¾å€¼

    # è½‰æ›ç‚ºåˆ†é¡å•é¡Œ
    y_true_class = [1 if rating >= threshold else 0 for rating in y_true]
    y_pred_class = [1 if rating >= threshold else 0 for rating in y_pred]

    # è¨ˆç®—æ··æ·†çŸ©é™£åŠå…¶ä»–æŒ‡æ¨™
    cm = confusion_matrix(y_true_class, y_pred_class)
    accuracy = accuracy_score(y_true_class, y_pred_class)
    precision = precision_score(y_true_class, y_pred_class, zero_division=0)
    recall = recall_score(y_true_class, y_pred_class, zero_division=0)
    f1 = f1_score(y_true_class, y_pred_class, zero_division=0)
    class_report = classification_report(y_true_class, y_pred_class, zero_division=0)

    return rmse, mae, cm, accuracy, precision, recall, f1, class_report


# ===========================================================
# æ¨è–¦é¤å»³ä¸»ç¨‹å¼(åŸºæ–¼å…§å®¹æ¨è–¦ã€å”åŒéæ¿¾ã€æ··åˆæ¨è–¦)
# ===========================================================

# æ¨è–¦é¤å»³ä¸»ç¨‹å¼(å”åŒéæ¿¾)
def recommend_restaurants(user_id, num_recommendations):
    # print(f"ç›¸ä¼¼ç”¨æˆ¶åç¨±ç‚º: {train_user_restaurant_matrix.index}")
    if user_id not in train_user_restaurant_matrix.index:
        print(f"{user_id}é€™ç­†è³‡æ–™åœ¨çŸ©é™£å…§æ‰¾ä¸åˆ°ï¼Œè¦ä¸æ›ä¸€ç­†è©¦è©¦?")
        return []
    else:
        user_index = train_user_restaurant_matrix.index.get_loc(user_id)

        db_count = int(count_df['count'].iloc[0])

        print(f"é¤å»³è³‡æ–™é›†çš„ç­†æ•¸æ˜¯: {db_count}\n")

        # è¨­å®šè¼ƒå¤§çš„ n_neighbors å€¼ä»¥æ“´å¤§æ½›åœ¨æ¨è–¦ç¯„åœ
        n_neighbors = min(num_recommendations * random.randint(1, 5), len(train_user_restaurant_matrix))

        # å–å‡ºè·é›¢è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        distances, indices = knn.kneighbors(train_user_restaurant_matrix.iloc[user_index, :].values.reshape(1, -1),
                                            n_neighbors=n_neighbors)

        # å–å‡ºç›¸ä¼¼åº¦æœ€é«˜çš„å‰5å€‹ä½¿ç”¨è€…çš„ç´¢å¼•å’Œè·é›¢
        top_5_indices = indices.flatten()[1:6]  # æ’é™¤è‡ªå·±ï¼Œå–å‡ºå‰5å€‹ç›¸ä¼¼ç”¨æˆ¶çš„ç´¢å¼•
        top_5_distances = distances.flatten()[1:6]  # å–å‡ºå‰5å€‹ç›¸ä¼¼ç”¨æˆ¶çš„è·é›¢

        print(f"èˆ‡{user_id}ç›¸ä¼¼åº¦æœ€é«˜çš„å‰5å€‹ä½¿ç”¨è€…åŠå…¶è·é›¢æ˜¯ï¼š\n")

        for idx, (user_idx, distance) in enumerate(zip(top_5_indices, top_5_distances), 1):
            similar_user_id = train_user_restaurant_matrix.index[user_idx]
            print(f"{idx}. ä½¿ç”¨è€…ID: {similar_user_id}, ç›¸ä¼¼åº¦è·é›¢: {distance:.2f}")

            # å–å‡ºç›¸ä¼¼ç”¨æˆ¶çš„è©•åˆ†è³‡æ–™
            similar_user_ratings = train_data[train_data['user_id'] == similar_user_id]
            printed_restaurant_ids = set()  # ç”¨æ–¼è·Ÿè¸ªå·²æ‰“å°çš„é¤å»³ID

            for _, row in similar_user_ratings.iterrows():
                restaurant_id = row['restaurant_id']
                if restaurant_id not in printed_restaurant_ids:
                    print(
                        f"======================================\né¤å»³ID: {row['restaurant_id']}\nè©•åˆ†: {row['rating']}\né¤å»³åç¨±: {row['restaurant_name']}\næ‰€åœ¨åŸå¸‚: {row['city']}\n======================================")
                    printed_restaurant_ids.add(restaurant_id)

        # éš¨æ©Ÿé¸æ“‡éƒ¨åˆ†é„°å±…çš„ç´¢å¼•
        random_neighbors = random.sample(range(1, len(distances.flatten())),
                                         min(num_recommendations * 1, len(distances.flatten()) - 1))

        # ç”¨æ–¼å­˜æ”¾é¤å»³
        recommended_restaurants = []

        # ç”¨æ–¼è¿½è¹¤å·²æ¨è–¦çš„é¤å»³ID
        recommended_ids = set()

        # ç”¨æ–¼å­˜æ”¾åŸå¸‚æ•¸é‡
        city_count = {}

        for i in random_neighbors:
            similar_user_id = train_user_restaurant_matrix.index[indices.flatten()[i]]
            similar_user_ratings = train_data[train_data['user_id'] == similar_user_id]

            for _, row in similar_user_ratings.iterrows():
                restaurant_id = row['restaurant_id']
                if restaurant_id not in recommended_ids:
                    # å–å¾—ç¶“ç·¯åº¦
                    restaurant_location = restaurants_df[restaurants_df['restaurant_id'] == restaurant_id]
                    # è‹¥ç¶“ç·¯åº¦ç‚ºç©ºå°±è·³é
                    if restaurant_location.empty:
                        continue
                    # å–å¾—ç›¸é—œè³‡è¨Š
                    restaurant_name = id_to_name.get(restaurant_id)
                    redirection_urls = redirection_url_to_id.get(restaurant_id)
                    navigation_urls = navigation_url_to_id.get(restaurant_id)
                    city = city_url_to_id.get(restaurant_id)
                    # ç¢ºä¿æ¯å€‹åŸå¸‚æ¨è–¦çš„é¤å»³ä¸è¶…éæŒ‡å®šæ•¸é‡
                    if city_count.get(city, 0) <= 1:
                        recommended_restaurants.append((restaurant_name, restaurant_location['latitude'].values[0],
                                                        restaurant_location['longitude'].values[0], redirection_urls,
                                                        navigation_urls, city))
                        recommended_ids.add(restaurant_id)
                        city_count[city] = city_count.get(city, 0) + 1
                    # å¦‚æœæ¨è–¦é¤å»³å·²æ»¿ï¼Œè·³å‡ºå…§å±¤å¾ªç’°
                    if len(recommended_restaurants) >= num_recommendations:
                        break
            # å¦‚æœæ¨è–¦é¤å»³å·²æ»¿ï¼Œè·³å‡ºå¤–å±¤å¾ªç’°
            if len(recommended_restaurants) >= num_recommendations:
                break
        # å¢åŠ éš¨æ©Ÿæ€§ï¼Œå¾æ¨è–¦åˆ—è¡¨ä¸­éš¨æ©Ÿé¸æ“‡æŒ‡å®šæ•¸é‡çš„é¤å»³
        if len(recommended_restaurants) > num_recommendations:
            recommended_restaurants = random.sample(recommended_restaurants, num_recommendations)
        else:
            recommended_restaurants = recommended_restaurants[:num_recommendations]
    # è¿”å›æœ€è¿‘çš„num_recommendationså®¶é¤å»³çš„åç¨±å’Œç¶“ç·¯åº¦
    return recommended_restaurants


# æ¨è–¦é¤å»³ä¸»ç¨‹å¼(å…§å®¹æ¨è–¦)
def content_based_recommendations(user_id, num_recommendations):
    # è¨ˆç®—é¤å»³ä¹‹é–“å…§å®¹ç›¸ä¼¼æ€§
    content_similarities = cosine_similarity(train_user_restaurant_matrix)

    # éš¨æ©Ÿé¸æ“‡10é–“ä½¿ç”¨è€…å¯èƒ½æ„Ÿèˆˆè¶£çš„é¤å»³
    num_random_restaurants = 10
    random_restaurant_indices = random.sample(range(len(restaurants_df)), num_random_restaurants)

    # ç”¨æ–¼å­˜æ”¾åŸå¸‚æ•¸é‡
    city_count = {}

    # æ ¹æ“šéš¨æ©Ÿé¸æ“‡çš„é¤å»³ï¼Œæ‰¾åˆ°ç›¸ä¼¼åº¦é«˜çš„é¤å»³
    similar_restaurants = []
    for idx in random_restaurant_indices:
        restaurant_similarities = content_similarities[idx]
        top_indices = restaurant_similarities.argsort()[::-1][:num_recommendations]
        for top_idx in top_indices:
            # è¶…éç´¢å¼•å€¼ç¯„åœå°±è·³é
            if top_idx >= len(restaurants_df):
                continue
            restaurant_id = restaurants_df.iloc[top_idx]['restaurant_id']
            # å¦‚æœé¤å»³IDä¸åœ¨åŸå…ˆçš„æ¨è–¦åˆ—è¡¨ä¸”é¤å»³åˆ—è¡¨çš„æ•¸é‡å°æ–¼æŒ‡å®šæ¨è–¦æ•¸é‡ï¼Œæ‰æ”¾åˆ°åˆ—è¡¨é€²è¡Œæ¨è–¦ï¼Œå¦å‰‡å°±ä¸æ¨è–¦
            if restaurant_id not in similar_restaurants and len(similar_restaurants) < num_recommendations:
                similar_restaurants.append(restaurant_id)
        # å¦‚æœé¤å»³åˆ—è¡¨å¤§æ–¼æ¨è–¦æ•¸é‡ï¼Œå°±è·³é
        if len(similar_restaurants) >= num_recommendations:
            break

    # æ ¹æ“šé¤å»³IDå’Œç›¸é—œè¨Šæ¯æ”¾å…¥æ¨è–¦åˆ—è¡¨
    recommended_restaurants = []

    for restaurant_id in similar_restaurants:
        restaurant_info = restaurants_df[restaurants_df['restaurant_id'] == restaurant_id]
        rating_info = ratings_df[ratings_df['restaurant_id'] == restaurant_id]
        if not restaurant_info.empty and not rating_info.empty:
            city = rating_info['city'].values[0]
            # ç¢ºä¿æ¯å€‹åŸå¸‚æ¨è–¦çš„é¤å»³ä¸è¶…éæŒ‡å®šæ•¸é‡
            if city_count.get(city, 0) < 1:
                recommended_restaurants.append((
                    restaurant_info['name'].values[0],
                    restaurant_info['latitude'].values[0],
                    restaurant_info['longitude'].values[0],
                    restaurant_info['redirection_url'].values[0],
                    restaurant_info['navigation_url'].values[0],
                    city
                ))
                city_count[city] = city_count.get(city, 0) + 1

    # å¦‚æœæ¨è–¦é¤å»³ä¸è¶³ num_recommendationsï¼Œéš¨æ©Ÿè£œè¶³ï¼Œä¸¦ç¢ºä¿åŸå¸‚ä¸é‡è¤‡
    while len(recommended_restaurants) < num_recommendations:
        random_idx = np.random.randint(len(restaurants_df))
        restaurant_id = restaurants_df.iloc[random_idx]['restaurant_id']
        restaurant_info = restaurants_df[restaurants_df['restaurant_id'] == restaurant_id]
        rating_info = ratings_df[ratings_df['restaurant_id'] == restaurant_id]
        # ç¢ºä¿restaurant_infoå’Œrating_infoä¸ç‚ºç©º
        if not restaurant_info.empty and not rating_info.empty:
            city = rating_info['city'].values[0]
            # ç¢ºä¿æ¯å€‹åŸå¸‚æ¨è–¦çš„é¤å»³ä¸è¶…éæŒ‡å®šæ•¸é‡
            if city_count.get(city, 0) < 1:
                recommended_restaurants.append((
                    restaurant_info['name'].values[0],
                    restaurant_info['latitude'].values[0],
                    restaurant_info['longitude'].values[0],
                    restaurant_info['redirection_url'].values[0],
                    restaurant_info['navigation_url'].values[0],
                    city
                ))
                city_count[city] = city_count.get(city, 0) + 1
    # å›å‚³æŒ‡å®šæ¨è–¦çš„é¤å»³æ•¸é‡
    return recommended_restaurants[:num_recommendations]


# æ¨è–¦é¤å»³ä¸»ç¨‹å¼(æ··åˆæ¨è–¦)
def hybrid_recommendations(user_id, num_recommendations):
    if user_id not in train_user_restaurant_matrix.index:
        print(f"{user_id}é€™ç­†è³‡æ–™åœ¨çŸ©é™£å…§æ‰¾ä¸åˆ°ï¼Œè¦ä¸æ›ä¸€ç­†è©¦è©¦?")
        return []
    else:
        # ç”¨æ–¼å­˜æ”¾åŸå¸‚æ•¸é‡
        city_count = {}
        # å–å¾—å”åŒéæ¿¾æ¨è–¦é¤å»³
        cf_recommendations = recommend_restaurants(user_id, num_recommendations)
        # å–å¾—å…§å®¹æ¨è–¦é¤å»³
        content_recommendations = content_based_recommendations(user_id, num_recommendations)
        # å°‡å…©å€‹æ¨è–¦çµæœåˆä½µ
        all_recommendations = cf_recommendations + content_recommendations
        # å­˜æ”¾å”¯ä¸€çš„æ¨è–¦çµæœ
        unique_recommendations = []
        seen = set()
        for rec in all_recommendations:
            # æ²’æœ‰æ¨è–¦éçš„é¤å»³æ‰é€²è¡Œæ¨è–¦
            if rec not in seen:
                # å–å¾—æ‰€æœ‰åŸå¸‚
                city = rec[5]
                # ç¢ºä¿æ¯å€‹åŸå¸‚æ¨è–¦çš„é¤å»³ä¸è¶…éæŒ‡å®šæ•¸é‡
                if city_count.get(city, 0) < 1:
                    unique_recommendations.append(rec)
                    city_count[city] = city_count.get(city, 0) + 1
                seen.add(rec)

        if len(unique_recommendations) > num_recommendations:
            unique_recommendations = random.sample(unique_recommendations, num_recommendations)

    return unique_recommendations[:num_recommendations]


# ===========================================================
# LINE APIä¸²æ¥
# ===========================================================

# è™•ç†LINEè¨Šæ¯
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return 'OK'


user_states = {}  # åˆå§‹åŒ–ä½¿ç”¨è€…ç‹€æ…‹å­—å…¸


# è™•ç†æ–‡å­—è¨Šæ¯
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    text = event.message.text.strip()
    user_id = event.source.user_id
    profile = line_bot_api.get_profile(user_id)
    user_name = profile.display_name

    if text.lower() == 'help' or text in ['ä½¿ç”¨é ˆçŸ¥', 'ä½¿ç”¨èªªæ˜', 'æç¤º', 'æç¤ºæ–‡å­—']:
        message = TextSendMessage(
            text=f"æ‚¨å¥½ï¼š{user_name}\næ„Ÿè¬æ‚¨åŠ å…¥å¥½å‹ğŸ˜˜\næ­¡è¿ä½¿ç”¨é»é¤æ¨è–¦æ©Ÿå™¨äººğŸ˜ï¼\nğŸ½ï¸ ä¸‹åˆ—ç‚ºä½¿ç”¨æ•™å­¸(ç¸½å…±ç‚ºå…©å€‹æ­¥é©Ÿ)ï¼š\n1.è«‹è¼¸å…¥æ‚¨çš„ user_id ä¾†ç²å–é¤å»³æ¨è–¦ï¼Œä¾‹å¦‚ï¼š1\n2.ï¸ ï¸æ‚¨æƒ³è¦æ¨è–¦å¹¾å®¶é¤å»³ï¼Ÿè«‹è¼¸å…¥æ•¸å­—ï¼Œä¾‹å¦‚ï¼š3\nå‚™è¨»ï¼šuser_idç¯„åœåœ¨1~1039ï¼Œè«‹è¼¸å…¥åœ¨é€™ç¯„åœç•¶ä¸­çš„ä»»æ„æ•¸å­—!!!"
        )
        line_bot_api.reply_message(event.reply_token, message)
        return

    if user_id in user_states:
        if user_states[user_id]['step'] == 'ask_for_count':
            try:
                num_recommendations = int(text)

                if num_recommendations > 10 or num_recommendations < 1:
                    line_bot_api.reply_message(
                        event.reply_token,
                        TextSendMessage(text='ğŸš«æœ€å¤šåªèƒ½æ¨è–¦10å®¶é¤å»³ï¼Œæœ€å°‘æ¨è–¦1å®¶é¤å»³ï¼Œè«‹é‡æ–°è¼¸å…¥ï¼')
                    )
                    return  # åœ¨é€™è£¡åŠ ä¸Š returnï¼Œçµ‚æ­¢å¾ŒçºŒç¨‹å¼ç¢¼åŸ·è¡Œ
                else:
                    user_states[user_id]['num_recommendations'] = num_recommendations
                    user_states[user_id]['step'] = 'done'
                    # å–å¾—æ¨è–¦çš„é¤å»³
                    recommendations = recommend_restaurants(user_states[user_id]['user_id'], num_recommendations)
                    if recommendations:
                        carousel_data = []
                        for name, lat, lon, redirection_urls, navigation_urls in recommendations:
                            carousel_data.append(
                                {
                                    'thumbnail_image_url': 'https://firebasestorage.googleapis.com/v0/b/mlimage-64f65.appspot.com/o/cake.jpg?alt=media&token=f9081587-8b75-4074-b1dc-4f98410397c1',
                                    # æ›¿æ›æˆæœ‰æ•ˆçš„åœ–ç‰‡URL
                                    'title': name,
                                    'text': f"ç¶“åº¦ï¼š{lon}ï¼Œç·¯åº¦ï¼š{lat}",
                                    'actions': [
                                        {'type': 'uri', 'label': 'é»æˆ‘å°è¦½è‡³googlemaps', 'uri': navigation_urls},
                                        {'type': 'uri', 'label': 'é»æˆ‘å°è¦½è‡³foodpanda', 'uri': redirection_urls},
                                        {'type': 'message', 'label': 'ä½¿ç”¨èªªæ˜',
                                         'text': 'ä½¿ç”¨èªªæ˜'}
                                    ]
                                }
                            )

                        columns = []
                        for item in carousel_data:
                            actions = []
                            for action in item['actions']:
                                if action['type'] == 'uri':
                                    actions.append(URIAction(label=action['label'], uri=action['uri']))
                                elif action['type'] == 'postback':
                                    actions.append(PostbackAction(label=action['label'], data=action['data'],
                                                                  text=action.get('text', None)))
                                elif action['type'] == 'message':
                                    actions.append(MessageAction(label=action['label'], text=action['text']))

                            column = CarouselColumn(
                                thumbnail_image_url=item['thumbnail_image_url'],
                                title=item['title'],
                                text=item['text'],
                                actions=actions
                            )
                            columns.append(column)

                        carousel_template = CarouselTemplate(columns=columns)
                        template_message = TemplateSendMessage(
                            alt_text='æ¨è–¦é¤å»³',
                            template=carousel_template
                        )
                        line_bot_api.reply_message(event.reply_token, template_message)
                    else:
                        message = TextSendMessage(text="æ‰¾ä¸åˆ°ç›¸é—œé¤å»³æ¨è–¦è³‡æ–™ã€‚")
                        line_bot_api.reply_message(event.reply_token, message)

                # æ¸…é™¤ç”¨æˆ·çŠ¶æ€
                del user_states[user_id]

            except ValueError:
                line_bot_api.reply_message(
                    event.reply_token,
                    TextSendMessage(text="ğŸš«è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ï¼")
                )
        return

    try:
        user_id_input = int(text)
        if (user_id_input < 1 or user_id_input > 1039):
            line_bot_api.push_message(user_id, TextSendMessage(text='ğŸš«æ‚¨è¼¸å…¥çš„userä¸å­˜åœ¨ï¼Œè«‹é‡æ–°è¼¸å…¥!!!'))
        else:
            user_states[user_id] = {
                'step': 'ask_for_count',
                'user_id': user_id_input
            }
            message = TextSendMessage(
                text="ğŸ½ï¸ æ‚¨æƒ³è¦æ¨è–¦å¹¾å®¶é¤å»³ï¼Ÿè«‹è¼¸å…¥æ•¸å­—ï¼Œä¾‹å¦‚ï¼š3"
            )
            line_bot_api.reply_message(event.reply_token, message)
    except ValueError:
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="ğŸš« è«‹è¼¸å…¥æœ‰æ•ˆçš„ user_idï¼ä¾‹å¦‚ï¼š1")
        )


# LINE WEBHOOKä¸²æ¥é€²å…¥é»
@app.route("/", methods=['POST'])
def linebot():
    body = request.get_data(as_text=True)  # å–å¾—æ”¶åˆ°çš„è¨Šæ¯å…§å®¹
    signature = request.headers['X-Line-Signature']  # åŠ å…¥å›å‚³çš„ headers
    try:
        handler.handle(body, signature)  # ç¶å®šè¨Šæ¯å›å‚³çš„ç›¸é—œè³‡è¨Š
        json_data = json.loads(body)  # json æ ¼å¼åŒ–è¨Šæ¯å…§å®¹
        tk = json_data['events'][0]['replyToken']  # å–å¾—å›å‚³è¨Šæ¯çš„ Token
        event_type = json_data['events'][0]['type']  # å–å¾—äº‹ä»¶é¡å‹
    except InvalidSignatureError:
        abort(400)
    except Exception as e:
        print(f"Error: {e}")  # å°å‡ºéŒ¯èª¤è¨Šæ¯
        print(body)  # å°å‡ºæ”¶åˆ°çš„å…§å®¹

    return 'OK'  # é©—è­‰ Webhook ä½¿ç”¨ï¼Œä¸èƒ½çœç•¥


# è™•ç†åŠ å…¥å¥½å‹äº‹ä»¶
@handler.add(FollowEvent)
def handle_follow(event):
    user_id = event.source.user_id
    profile = line_bot_api.get_profile(user_id)
    user_name = profile.display_name

    # æ–°ç”¨æˆ¶æœƒçœ‹åˆ°çš„è¨Šæ¯
    welcome_message = f"æ‚¨å¥½ï¼š{user_name}\næ„Ÿè¬æ‚¨åŠ å…¥å¥½å‹ğŸ˜˜\næ­¡è¿ä½¿ç”¨é»é¤æ¨è–¦æ©Ÿå™¨äººğŸ˜ï¼\nğŸ½ï¸ ä¸‹åˆ—ç‚ºä½¿ç”¨æ•™å­¸(ç¸½å…±ç‚ºå…©å€‹æ­¥é©Ÿ)ï¼š\n1.è«‹è¼¸å…¥æ‚¨çš„ user_id ä¾†ç²å–é¤å»³æ¨è–¦ï¼Œä¾‹å¦‚ï¼š1\n2.ï¸ ï¸æ‚¨æƒ³è¦æ¨è–¦å¹¾å®¶é¤å»³ï¼Ÿè«‹è¼¸å…¥æ•¸å­—ï¼Œä¾‹å¦‚ï¼š3\nå‚™è¨»ï¼šuser_idç¯„åœåœ¨1~1039ï¼Œè«‹è¼¸å…¥åœ¨é€™ç¯„åœç•¶ä¸­çš„ä»»æ„æ•¸å­—!!!"
    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text=welcome_message)
    )


# è™•ç†å°é–å’Œé‡æ–°åŠ å…¥å¥½å‹äº‹ä»¶
@handler.add(UnfollowEvent)
def handle_unfollow(event):
    user_id = event.source.user_id
    profile = line_bot_api.get_profile(user_id)
    user_name = profile.display_name

    # æ–°ç”¨æˆ¶æœƒçœ‹åˆ°çš„è¨Šæ¯
    welcome_message = f"æ­¡è¿åŠ å…¥, {user_name}ï¼ğŸ½ï¸ è«‹è¼¸å…¥æ‚¨çš„ user_id ä¾†ç²å–é¤å»³æ¨è–¦ï¼Œä¾‹å¦‚ï¼š1"
    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text=welcome_message)
    )


# è™•ç†åœ°é»è¨Šæ¯äº‹ä»¶
@handler.add(MessageEvent, message=LocationMessage)
def handle_location_message(event):
    location = event.message  # å–å¾—åœ°é»è¨Šæ¯
    reply = f"åœ°é»åç¨±ï¼š{location.title}\nåœ°å€ï¼š{location.address}\nç·¯åº¦ï¼š{location.latitude}\nç¶“åº¦ï¼š{location.longitude}"
    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text=reply)
    )


# ===========================================================
# æ¨è–¦ä¸»ç¨‹å¼é€²å…¥é»
# ===========================================================

# ä½¿ç”¨éš¨æ©Ÿäº‚æ•¸æŠ½å–é¤å»³è³‡æ–™é›†è£¡ä»»5å€‹æ•¸å­—ç•¶user_id
user_ids = random.sample(range(1, int(count_df['count'].iloc[0])), 1)
num_recommendations = 5
print(f'''
# ===========================================================
# æ­¡è¿ä½¿ç”¨é»é¤æ¨è–¦ç³»çµ±
# ===========================================================
''')
for user_id in user_ids:
    recommendations = hybrid_recommendations(user_id, num_recommendations)
    print(f"æ¨è–¦çµ¦ä½¿ç”¨è€…ã€{user_id}ã€‘çš„é¤å»³å¦‚ä¸‹ï¼š\n")
    for name, lat, lon, redirection_url, navigation_url, city in recommendations:
        print(f"é¤å»³åç¨±ï¼š{name}\nç¶“åº¦ï¼š{lon}\nç·¯åº¦ï¼š{lat}\næ‰€åœ¨åŸå¸‚ï¼š{city}")
        print("=============================")
# è©•ä¼°æ¨¡å‹æº–ç¢ºåº¦
results = evaluate_model()
if results:
    rmse, mae, cm, accuracy, precision, recall, f1, class_report = results
    print(f"RMSE:{rmse:.2f}")
    print(f"MAE:{mae:.2f}")
    print("=============================")
    print(f"æº–ç¢ºç‡:{accuracy:.2f}")
    print(f"ç²¾ç¢ºç‡:{precision:.2f}")
    print(f"å¬å›ç‡:{recall:.2f}")
    print(f"F1è©•åˆ†:{f1:.2f}")
    print("=============================")
    print("å ±è¡¨:\n", class_report)

# ===========================================================
# LINEä¸»ç¨‹å¼é€²å…¥é»
# ===========================================================
# if __name__ == "__main__":
#     warnings.filterwarnings("ignore", category=LineBotSdkDeprecatedIn30)
#     app.run(debug=True, host='0.0.0.0', port=5000)
